\documentclass{article}
\usepackage{a4wide}
\usepackage{alltt}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{latexsym}
\usepackage{pig}

\newcommand{\fbx}[1]{\framebox{\ensuremath{#1}}}
\newcommand{\la}[2]{\backslash\;#1\;\texttt{->}\;#2}
\newcommand{\pl}[2]{\texttt{(}#1\;\texttt{+}\;#2\texttt{)}}

\begin{document}
\title{LAM --- Semantic Variations}
\author{Neil Ghani and Conor McBride}
\maketitle

Our grammar of $\lambda$-terms is given by
\begin{verbatim}
<term>
  ::= <var>
    | <term> <term>
    | \ <var> -> <term>
    | <number>
    | (<term> + <term>)
\end{verbatim}
If we were real purists, we would omit numbers and addition:
we include them to represent `ordinary' computation, where
the job of the $\lambda$-terms is to route data to whichever
computation is appropriate.


\section{Small Step Reduction}

We write $f$, $s$ and $t$ for terms, and $m$ and $n$ for numerical constants.
Our judgement form is
\[
  \fbx{s\leadsto t}
\]
with $s$ as an input and $t$ as an output.

The key axioms which do the work are $\beta$-reduction and numerical addition.
\[
  \Axiom{(\la x{t[x]})\;s \leadsto t[s]}
  \qquad
  \Axiom{\pl mn \leadsto m+n}
\]
They are not, however, enough: before you make a reduction step, you have to find a redex! We add \emph{contextual closure} rules:
\[\begin{array}{c}
  \Rule{f\leadsto f'}
  {f\;s \leadsto f'\:s}
  \qquad
  \Rule{s\leadsto s'}
  {f\;s \leadsto f\:s'}
  \\
  \Rule{t[x]\leadsto t'[x]}
  {\la x{t[x]} \leadsto \la x{t'[x]}}
  \\
  \Rule{s \leadsto s'}
  {\pl st \leadsto \pl{s'}t}
  \qquad
  \Rule{t \leadsto t'}
  {\pl st \leadsto \pl s{t'}}
\end{array}\]
The contextual closure rules are very far from arbitrary: they are generated from the grammar, with one rule for every way to put a subterm inside a term. Their impact is to allow $\beta$-reduction and numerical addition \emph{anywhere} inside a term. These rules are highly nondeterministic: when there are multiple redexes, they do not tell you which one to choose.


\section{Big Step Reduction}

Here is one way to give a big step semantics for LAM. Before we can write the rules, we need to say `what success looks like': to what \emph{values} are we
trying to compute the terms?

In our language of functions and numbers, let us say that a function is a value if it is ready to be applied, and a number is a value if it is ready to be added.
\begin{verbatim}
<value>
  ::= \ <var> -> <term>
    | <number>
\end{verbatim}
Note that for functions we make no demands on the body of the abstraction.
Let us write $u$ and $v$ for values. Our judgement form is
\newcommand{\lbs}[2]{#1\,\Downarrow\,#2}
\[\fbx{\lbs tv}
\]
with $t$ as input and $v$ as output.
We have only four rules. Two tell us how to stop
\[
  \Axiom{\lbs{\la x{t[x]}}{\la x{t[x]}}}
  \qquad
  \Axiom{\lbs nn}
\]
and two tell us how to go.
\[
  \Rule{\lbs{f}{\la x{t[x]}}\quad \lbs{t[s]}v}
  {\lbs{f\:s}v}
  \qquad
  \Rule{\lbs sm\quad \lbs tn}
  {\lbs{\pl s t}{m+n}}
\]
There are several things to notice about this semantics:
\begin{itemize}
\item It does not give \emph{every} term a value. (Think about which terms do not get a value, and why. There are several kinds of `bad'.)
\item It has a deterministic evaluation strategy.
\item It never computes inside the body of an abstraction: rather, it leaves the body untouched until the function's argument turns up.
\item It is still reliant on substitution.
\item A function's arguments are not evaluated until after substitution: this is a win if the bound variable is unused, but unfortunate if it is used a lot.
\end{itemize}


\section{Closures and Environments}

There is no particularly good reason why values should be a subset of terms.
They could be something apart. Here is a way to represent function values more efficiently, getting rid of substitution.
\begin{verbatim}
<val>
  ::= [<env>] <var> -> <term>
    | <number>

<env>
  ::=
    | <env>, <var> = <val>
\end{verbatim}
Our function values are now given as structures called \emph{closures} which pack up an \emph{environment} along with an abstraction. An environment is a mapping of variables to values. A closure captures the situation where we are not quite ready to evaluate the body of an abstraction: we know the values of all the \emph{free} variables, but not the value of the bound variable.

We write $u$ and $v$ for `vals' and $\gamma$ for environments. Our judgement form now takes an environment, to explain what the free variables mean.
\[
  \fbx{\gamma | \lbs tv}
\]
We expect every free variable to have an entry in the environment. We make the further assumption that all the free variables have different names: this is achievable by $\alpha$-conversion (but there is a better way).

\newcommand{\tto}{\,\texttt{->}\:}
We have one rule per construct.
\[\begin{array}{c}
  \Axiom{\gamma | \lbs{\la xt}{[\gamma]x \tto t}}
  \qquad
  \Axiom{\gamma | \lbs nn}
  \qquad
  \Axiom{\gamma,x=v,\gamma' | \lbs xv}
    \\
  \Rule{\gamma | \lbs f{[\gamma']x \tto t} \quad
    \gamma | \lbs su \quad
    \gamma',x=u | \lbs tv}
    {\gamma | \lbs{f\:s}v}
    \quad
    \Rule{\gamma | \lbs sm \quad \gamma | \lbs tn}
      {\gamma | \lbs{\pl st}{m+n}}
\end{array}\]

In a real implementation, we get rid of variable \emph{names} entirely.
We replace names variable usage sites by numbers called \emph{de Bruijn indices},
locally distinguished from numerical constants by a \# marker,
which tell us how many $\lambda$s to jump over before we find the one which bound the variable. That is
\[
  \la f{\la x{f\:(f\:x)}}
\]
becomes
\[
  \la{}{\la{}{\#1\:(\#1\:\#0)}}
\]
A de Bruijn index is just the thing to tell us \emph{where} in $\gamma$, now an
\emph{array} of values (with 0 the rightmost index), is the value we want.

Note that in this variation, an application's argument is evaluated agressively, so that its value is ready to go in the environment. That creates an extra risk of failure: an argument which contains some sort of error will cause a problem, even if that argument is never used by the function.


\section{Thunks}

Next comes a variation which is less aggressive about evaluating arguments.
The idea is that instead of evaluating things just before we put them into the environment, we evaluate things just after we take them out.

Our environments will thus contain terms, but that is not enough! In order to evaluate a term properly, we need to remember \emph{its} environment.
\begin{verbatim}
<thunkEnv>
  ::= 
    | <thunkEnv>, <var> = (<thunkEnv>|<term>)

<thunkVal>
  ::= [<thunkEnv>] <var> -> <term>
    | <number>
\end{verbatim}
A pair of an environment and an unvaluated term in that environment is called
a \emph{thunk}. A thunk stores all the information needed to start the evaluation process whenever the value is demanded. We call that \emph{forcing} the thunk.

Let us write $\theta$ for thunk environments. Our values change only in that closures store thunk environments instead of value environments: let us still use $u$ and $v$ for them.

The judgement form is thus
\[\theta | \lbs tv
\]

We still have one rule per construct, but the work happens in different places.
\[\begin{array}{c}
  \Axiom{\theta | \lbs{\la xt}{[\theta]x \tto t}}
  \qquad
  \Axiom{\theta | \lbs nn}
  \qquad
    \Rule{\theta | \lbs su}
         {\theta_0,x=(\theta|s),\theta_1 | \lbs xv}
    \\
  \Rule{\theta | \lbs f{[\theta']x \tto t} \quad
    \theta',x=(\theta|s) | \lbs tv}
    {\theta | \lbs{f\:s}v}
    \quad
    \Rule{\theta | \lbs sm \quad \theta | \lbs tn}
      {\theta | \lbs{\pl st}{m+n}}
\end{array}\]

See how work has moved from the application rule to the variable rule? Instead of evaluating the argument, we just thunk it (`thunk' is a verb as well as a noun),
carefully saving the environment appropriate to it. It is only when the value of a variable is demanded that we look up the thunk and force it, using the saved environment.


\section{Laziness}

The trouble with our previous variation is that it repeats the same evaluation process every time the same thunk is forced. That is, if a variable is used more than once, we do the same work more than once. The potential for woeful inefficiency results. There's a trick to get out of that: the first time a thunk is forced, \emph{overwrite} it with the resulting value. That is actually how Haskell works, and it is ironic that such a `pure' language with no assignment works deep down by sneakily mutating a store.

A \emph{thunk store}, $(\sigma,n)$ is an array $\sigma$ of $n$ entries
which are \emph{either} thunks or values, so that $\sigma.i$ is either a
thunk or a value if $i < n$. We write $\sigma(i:=v)$ to represent the array
updated by overwriting the thunk at $i$ with its value.
The number $n$ thus tells us how to allocate a new thunk in the store. We can now represent thunk environments as mappings $\ldots,x=i,\ldots$ from variables to indices in the thunk store.

Our judgement form is now
\[\fbx{(\sigma,n),\theta | \lbs tv, (\sigma',n')}
  \]
with the evolving thunk store as an extra input and an extra output.

We now have two rules for variables.
\[
  \Rule{\sigma.i=(\theta, s)\quad
        (\sigma,n),\theta \lbs sv, (\sigma', n')}
      {(\sigma,n),\theta_0,x=i,\theta_1 | \lbs xv, (\sigma'(i=v), n')}
      \qquad
  \Rule{\sigma.i=v}
      {(\sigma,n),\theta_0,x=i,\theta_1 | \lbs xv, (\sigma, n)}
\]
The application rule has to allocate a new thunk.
\[
\Rule{(\sigma_0,n_0),\theta | \lbs f{[\theta']x \tto t} (\sigma_1,n_1)\quad
    (\sigma_1(n_1:=(\theta|s)),n_1+1), \theta',x=n' | \lbs tv, (\sigma_2,n_2)}
    {(\sigma_0,n_0)\theta | \lbs{f\:s}v, (\sigma_2,n_2)}
\]
The other rules must take care to thread the mutation of the thunk store,
but are otherwise the same.
\[\begin{array}{c}
  \Axiom{(\sigma,n),\theta \lbs mm, (\sigma,n)}
  \qquad
  \Axiom{(\sigma,n),\theta | \lbs{\la xt}{[\theta]x \tto t}, (\sigma,n)}
  \\
  \Rule{(\sigma_0,n_0),\theta | \lbs sm, (\sigma_1,n_1) \quad
        (\sigma_1,n_1),\theta | \lbs tn, (\sigma_2,n_2)}
       {(\sigma_0,n_0),\theta | \lbs{\pl st}{m+n}, (\sigma_2,n_2)}
\end{array}  \]

\end{document}